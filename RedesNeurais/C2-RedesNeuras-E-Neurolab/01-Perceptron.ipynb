{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'Perceptron01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rasbt/mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mlxtend (machine learning extensions)\n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import numpy as np\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Perceptron\n",
    "#\n",
    "# eta = taxa de aprendizagem (learning rate) - valores entre 0 e 1\n",
    "# epoch = número de passos no dataset de treino\n",
    "#\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, eta = 0.01, epochs = 50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y):\n",
    "\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] +=  update * xi\n",
    "                self.w_[0] +=  update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.forward(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(url, header = None)\n",
    "df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo dados de duas classes: Setosa e versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "X = df.iloc[0:100, [0,2]].values\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "clf_perceptron = Perceptron(epochs = 10, eta = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "clf_perceptron.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_perceptron.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "print('Pesos (Weights): %s' % clf_perceptron.w_)\n",
    "plot_decision_regions(X, y, clf = clf_perceptron)\n",
    "plt.title('Perceptron')\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(clf_perceptron.errors_)+1), clf_perceptron.errors_, marker = 'o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Classificações Incorretas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o perceptron converge após a 6ª iteração e separa as duas classes de flores perfeitamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas com o Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o perceptron tenha classificado perfeitamente as duas classes de flores do dataset Iris, a convergência é um dos maiores problemas do perceptron. Frank Rosenblatt comprovou matematicamente que a regra de aprendizado do perceptron converge se as duas classes podem ser separadas por um hiperplano linear, mas surgem problemas se as classes não podem ser perfeitamente separadas por um hiperplano linear. Para demonstrar esse problema, usaremos duas classes e atributos diferentes do conjunto de dados Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'Perceptron02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versicolor e virginica\n",
    "y2 = df.iloc[50:150, 4].values\n",
    "y2 = np.where(y2 == 'Iris-virginica', -1, 1)\n",
    "X2 = df.iloc[50:150, [1,3]].values\n",
    "\n",
    "\n",
    "clf = Perceptron(epochs = 25, eta = 0.01)\n",
    "clf.train(X2, y2)\n",
    "\n",
    "plot_decision_regions(X2, y2, clf = clf)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(clf.errors_)+1), clf.errors_, marker = 'o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Classificações Incorretas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com uma menor taxa de treinamento, o perceptron não conseguiu encontrar um bom limite de decisão uma vez que uma ou mais amostras serão sempre mal classificadas em cada época (cada passada), de modo que a regra de aprendizagem nunca para de atualizar os pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra falha do algoritmo perceptron é que ele para de atualizar os pesos assim que todas as amostras são classificadas corretamente. Nossa intuição nos diz que um limite de decisão com uma grande margem entre as classes provavelmente tem um erro de generalização melhor do que o limite de decisão do perceptron. Os classificadores de grande margem, como as Máquinas de Suporte Vector (SVM), resolveriam este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número Total de Classificações Incorretas: %d of 100' % (y2 != clf.predict(X2)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaline e Regra Delta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O perceptron certamente era muito popular no momento de sua descoberta, no entanto, levou apenas alguns anos até que Bernard Widrow e seu aluno de doutorado Tedd Hoff propuseram a ideia do Adaline (Adaptive Linear Neuron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em contraste com a regra perceptron, a regra delta do Adaline atualiza os pesos com base em uma função de ativação linear em vez de uma função de etapa unitária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'Adaline01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo uma função contínua, uma das maiores vantagens da função de ativação linear (Adaline) sobre a função de etapa unitária (Perceptron) é a possibilidade de diferenciar a saída. Esta propriedade permite definir uma função de custo J(w) que podemos minimizar para atualizar nossos pesos. No caso da função de ativação linear, podemos definir a função de custo J(w) como a soma de erros quadráticos (SSE), que é semelhante à função de custo que é minimizada em regressão linear com mínimos quadrados ordinários (OLS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para minimizar a função de custo do SSE, usaremos gradiente descendente, um algoritmo de otimização simples e útil que é frequentemente usado no aprendizado de máquinas para encontrar o mínimo local de sistemas lineares.\n",
    "\n",
    "Antes de chegar à parte divertida (cálculo), vamos considerar uma função de custo convexo para um único peso. Conforme ilustrado na figura abaixo, podemos descrever o princípio por trás da descida do gradiente como \"descer uma colina\" até atingir um mínimo local ou global. Em cada passo, damos um passo na direção oposta do gradiente, e o tamanho do passo é determinado pelo valor da taxa de aprendizagem, bem como pela inclinação do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'Gradiente01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline com Gradiebte Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaline com Gradiebte Descendente\n",
    "class AdalineGD(object):\n",
    "\n",
    "    def __init__(self, eta=0.01, epochs = 50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y):\n",
    "\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            output = self.forward(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, muitas vezes é necessário alguma experimentação para encontrar uma boa taxa de aprendizado para convergência ótima, assim, vamos começar por traçar o custo para duas taxas de aprendizagem diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineGD(epochs=10, eta=0.01).train(X, y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), np.log10(ada.cost_), marker='o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('log(Sum Squared Error - SSE)')\n",
    "plt.title('Adaline - Learning rate 0.01')\n",
    "plt.show()\n",
    "\n",
    "ada = AdalineGD(epochs=10, eta=0.0001).train(X, y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), ada.cost_, marker='o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Sum Squared Error - SSE')\n",
    "plt.title('Adaline - Learning rate 0.0001')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os 2 plots acima enfatizam bem a importância de traçar curvas de aprendizagem ilustrando dois problemas mais comuns com gradiente descendente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Se a taxa de aprendizado for muito grande, o gradiente descendente superará os mínimos e divergirá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Se a taxa de aprendizagem for muito pequena, o algoritmo exigirá muitas épocas (passagens) para convergir e pode ficar preso nos mínimos locais com mais facilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'Gradiente02.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gradiente descendente é também um bom exemplo porque a **escala (padronização) de atributos** é importante para muitos algoritmos de aprendizagem de máquina. Não só é mais fácil encontrar uma taxa de aprendizado apropriada se as características estiverem na mesma escala, mas também muitas vezes leva a uma convergência mais rápida e pode impedir que os pesos se tornem muito pequenos (estabilidade numérica)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sem Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineGD(epochs = 15, eta = 0.01)\n",
    "\n",
    "ada.train(X, y)\n",
    "plot_decision_regions(X, y, clf=ada)\n",
    "plt.title('Adaline - Gradient Descent')\n",
    "plt.xlabel('sepal length [padronizado]')\n",
    "plt.ylabel('petal length [padronizado]')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len( ada.cost_)+1), ada.cost_, marker = 'o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Sum Squared Error - SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Com Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando os atributos\n",
    "X_std = np.copy(X)\n",
    "X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()\n",
    "X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineGD(epochs = 15, eta = 0.01)\n",
    "\n",
    "ada.train(X_std, y)\n",
    "plot_decision_regions(X_std, y, clf=ada)\n",
    "plt.title('Adaline - Gradient Descent')\n",
    "plt.xlabel('sepal length [padronizado]')\n",
    "plt.ylabel('petal length [padronizado]')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len( ada.cost_)+1), ada.cost_, marker = 'o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Sum Squared Error - SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning com Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seção anterior foi sobre a aprendizagem baseada no gradiente descendente em \"lote\" (batch). As atualizações \"em lote\" referem-se ao fato de que a função de custo é minimizada com base no conjunto completo de dados de treinamento. Se pensarmos na regra do perceptron, lembramos que ela realizou a atualização de peso de forma incremental após cada amostra de treinamento individual. Essa abordagem também é chamada de aprendizagem \"online\", e de fato, é assim que Adaline foi descrita pela primeira vez por Bernard Widrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de atualização incremental dos pesos é também chamado de Stochastic Gradient Descent, uma vez que aproxima a minimização da função de custo. Embora a abordagem da Stochastic Gradient Descent possa soar inferior ao gradiente descendente devido à sua natureza \"estocástica\" e à direção \"aproximada\" (gradiente), pode ter certas vantagens na prática. Muitas vezes, a descida de gradiente estocástica converge muito mais rápido do que a descida de gradiente, uma vez que as atualizações são aplicadas imediatamente após cada amostra de treinamento. A descida de gradiente estocástica é computacionalmente mais eficiente, especialmente para conjuntos de dados muito grandes. Outra vantagem do aprendizado on-line é que o classificador pode ser atualizado imediatamente à medida que novos dados de treinamento chegam, por exemplo, como em aplicativos da Web, e dados de treinamento antigos podem ser descartados se o armazenamento for um problema. Em sistemas de aprendizagem mecânica de grande escala, também é prática comum usar os chamados \"mini-lotes\", um compromisso com uma convergência mais suave do que a descida de gradiente estocástica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo Adaline com Gradient Descent\n",
    "class AdalineSGD(object):\n",
    "\n",
    "    def __init__(self, eta = 0.01, epochs = 50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y, reinitialize_weights = True):\n",
    "\n",
    "        if reinitialize_weights:\n",
    "            self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for xi, target in zip(X, y):\n",
    "                output = self.forward(xi)\n",
    "                error = (target - output)\n",
    "                self.w_[1:] += self.eta * xi.dot(error)\n",
    "                self.w_[0] += self.eta * error\n",
    "\n",
    "            cost = ((y - self.activation(X))**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineSGD(epochs = 15, eta = 0.01)\n",
    "\n",
    "ada.train(X_std, y)\n",
    "plot_decision_regions(X_std, y, clf=ada)\n",
    "plt.title('Adaline - Stochastic Gradient Descent')\n",
    "plt.xlabel('sepal length [padronizado]')\n",
    "plt.ylabel('petal length [padronizado]')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len( ada.cost_)+1), ada.cost_, marker = 'o')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Sum Squared Error - SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
