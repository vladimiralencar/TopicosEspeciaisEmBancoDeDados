{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset Boston Houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-residential acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per 10,000 \n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population \n",
    "14. TARGET: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o dataset\n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()['target'] # variável preditora ou Classe ou Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando número de observações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = len(dataset)\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:,:-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a matriz\n",
    "X = dataset.iloc[:,:-1]\n",
    "matriz_corr = X.corr()\n",
    "print (matriz_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de Correlação com a variável preditora\n",
    "mt = pd.DataFrame(dataset.values, columns=dataset.columns)\n",
    "mt_corr = mt.corr()\n",
    "print (abs(mt_corr['target']).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a matriz de correlação (somente os atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Correlation Plot\n",
    "def visualize_correlation_matrix(data, hurdle = 0.0):\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    ax = fig.add_subplot(111)\n",
    "    R = np.corrcoef(data, rowvar = 0)\n",
    "    R[np.where(np.abs(R) < hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap = mpl.cm.coolwarm, alpha = 0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticklabels(dataset.columns[:-1], minor = False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(dataset.columns[:-1], minor = False)\n",
    "    plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off')   \n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o Plot\n",
    "visualize_correlation_matrix(X, hurdle = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar Feature Scaling através de Padronização ou Normalização. <br />Normalização aplica escala aos dados com intervalos entre 0 e 1. <br />A Padronização divide a média pelo desvio padrão para obter uma unidade de variância. <br />Vamos usar a Padronização (StandardScaler) pois nesse caso esta técnica ajusta os coeficientes e torna a superfície de erros mais \"tratável\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = StandardScaler()\n",
    "Xst = standardization.fit_transform(X)\n",
    "original_means = standardization.mean_\n",
    "originanal_stds = standardization.scale_\n",
    "print('Dataset Original')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Padronizado')\n",
    "dstd = pd.DataFrame(Xst, columns=boston.feature_names)\n",
    "dstd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstd.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desfazendo a Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXst = pd.DataFrame(Xst, columns=boston.feature_names)\n",
    "dfXst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinv = standardization.inverse_transform(Xst)\n",
    "dfinverser = pd.DataFrame(Xinv, columns=boston.feature_names)\n",
    "dfinverser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo\n",
    "modelo = linear_model.LinearRegression() #normalize = False, fit_intercept = True)\n",
    "modelo.fit(Xst,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar os pesos dos Atributos ( yprev = w1X1 + w2X2 + ... + wnXn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, var in sorted(zip(modelo.coef_, dataset.columns[:-1]), reverse = True):\n",
    "    print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo com o R Squared (R²) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_est(X,y):\n",
    "    modelo = linear_model.LinearRegression(normalize = False, fit_intercept = True)\n",
    "    return r2_score(y, modelo.fit(X,y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('R2: %0.3f' %  r2_est(Xst,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gera o impacto de cada atributo no R² "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_impact = list()\n",
    "for j in range(X.shape[1]):\n",
    "    selection = [i for i in range(X.shape[1]) if i!=j]\n",
    "    r2_impact.append(((r2_est(X,y) - r2_est(X.values[:,selection],y)), dataset.columns[j]))\n",
    "    \n",
    "for imp, varname in sorted(r2_impact, reverse = True):\n",
    "    print ('%6.3f %s' %  (imp, varname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.056 LSTAT\n",
    " 0.044 RM\n",
    " 0.029 DIS\n",
    " 0.028 PTRATIO\n",
    " 0.011 NOX\n",
    " 0.011 RAD\n",
    " 0.006 B\n",
    " 0.006 ZN\n",
    " 0.006 CRIM\n",
    " 0.006 TAX\n",
    " 0.005 CHAS\n",
    " 0.000 INDUS\n",
    " 0.000 AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazer Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             CRIM\t  ZN  INDUS\t  CHAS\t     NOX      RM\t AGE\tDIS\t  RAD\t  TAX\t PTRATIO\tB\t   LSTAT\n",
    "Xteste = [   30.,   0.0, 11,      0.0,      0.5,     6. ,   80.2,  2.3,  1.0,    273.0,   21.2,      396.1,  7.4\n",
    "    ]\n",
    "\n",
    "standardization = StandardScaler()\n",
    "Xteste_escala = standardization.fit_transform(np.array(Xteste).reshape(1, -1)) \n",
    "#m = modelo.fit(X,y)\n",
    "#Xteste_norm = standardization.fit_transform(X)\n",
    "#modelo.predict(np.array(Xteste).reshape(1, -1))[0]\n",
    "\n",
    "modelo.predict(Xteste_escala)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xteste = [\n",
    "    [   0.02,   0.2, 7.01,   0.0,   0.5,  7.1,  45.2,  6.1,  3.0,    222,   15.2,      396.1,   5.4],\n",
    "    [   0.01,   0.1,11.01,   0.0,   0.6,  6.1,  80.2,  2.5,  1.0,    273,   21.2,      396.9,   12.6],\n",
    "]\n",
    "\n",
    "\n",
    "Xteste_escala = standardization.fit_transform(np.array(Xteste)) \n",
    "\n",
    "modelo.predict(np.array(Xteste_escala))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas para Algoritmos de Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['y_prev'] = modelo.predict(Xst)\n",
    "#dataset['Erro'] = dataset['y_prev'] - dataset['target'] \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Erro'] = abs (dataset['y_prev'] - dataset['target'] )\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Erro.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE - Mean Absolute Error\n",
    "É a soma da diferença absoluta entre previsões e valores reais.<br />\n",
    "Fornece uma ideia de quão erradas estão nossas previsões.<br />\n",
    "Valor igual a 0 indica que não há erro, sendo a previsão perfeita <br />\n",
    "(a exemplo do Logloss, a função cross_val_score inverte o valor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = 10\n",
    "resultado = model_selection.cross_val_score(modelo, Xst, y, cv = kfold, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "# Print do resultado\n",
    "print(\"MAE: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE - Mean Squared Error\n",
    "Similar ao MAE, fornece a magnitude do erro do modelo.<br />\n",
    "Ao extrairmos a raiz quadrada do MSE convertemos as unidades de volta ao original, \n",
    "o que pode ser útil para descrição e apresentação.<br />\n",
    "Isso é chamado RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = model_selection.KFold(num_folds, True, random_state = seed)\n",
    "\n",
    "resultado = model_selection.cross_val_score(modelo, Xst, y, cv = kfold, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# Print do resultado\n",
    "print(\"MSE: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar ao MAE, fornece a magnitude do erro do modelo.<br>\n",
    "Ao extrairmos a raiz quadrada do MSE convertemos as unidades de volta ao original, o que pode ser útil para descrição e apresentação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "print(\"RMSE: %.3f \" % (sqrt(abs(resultado.mean()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2  \n",
    "Essa métrica fornece uma indicação do nível de precisão das previsões em relação aos valores observados.<br />\n",
    "Também chamado de coeficiente de determinação.<br />\n",
    "Valores entre 0 e 1, sendo 1 o valor ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = model_selection.cross_val_score(modelo, Xst, y, cv = kfold, scoring = 'r2')\n",
    "\n",
    "# Print do resultado\n",
    "print(\"R^2: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
